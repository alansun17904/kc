# Certified Robustness via *Knowledge Continuity*

This repository is the official implementation of the experiments in *Achieving Domain-Independent Certified Robustness via Knowledge Continuity*. 
- *Knowledge continuity* reframes robustness as stability of a model's loss with respect to its hidden representations.
- Across input domains (continuous, discrete, non-metrizable), *knowledge continuity* provably certifies robustness of neural networks.
- *Knowledge continuity* can be provably achieved without compromising inferential performance.
- *Knowledge continuity* is practical. It can be tractably regularized and used as a diagnostic metric.

![knowledge-continuity](https://github.com/user-attachments/assets/d1571b0d-2429-4cb6-80f6-0776e69c344d)
